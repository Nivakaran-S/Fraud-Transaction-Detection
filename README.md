# Fraud Transaction Detection

A modular and configurable machine learning pipeline to detect fraudulent transactions.  
This project follows a **component-based architecture** with clearly defined stages for **data ingestion**, **data validation**, **data transformation**, and **model training**.

---

## ğŸ“Œ Features

- **Data Ingestion** â€“ Reads and loads raw transaction data from specified sources.
- **Data Validation** â€“ Validates schema, checks missing values, and ensures data integrity.
- **Data Transformation** â€“ Preprocesses data, handles missing values, encodes categorical variables, and scales features.
- **Model Training** â€“ Trains machine learning models on the processed data and generates evaluation metrics.
- **Logging & Exception Handling** â€“ Integrated logging and custom exception handling for better debugging.

---

## ğŸ›  Project Structure

FraudTransactionDetection/
â”‚
â”œâ”€â”€ components/
â”‚ â”œâ”€â”€ data_ingestion.py
â”‚ â”œâ”€â”€ data_validation.py
â”‚ â”œâ”€â”€ data_transformation.py
â”‚ â””â”€â”€ model_trainer.py
â”‚
â”œâ”€â”€ entity/
â”‚ â”œâ”€â”€ config_entity.py
â”‚
â”œâ”€â”€ exception/
â”‚ â””â”€â”€ exception.py
â”‚
â”œâ”€â”€ logging/
â”‚ â””â”€â”€ logger.py
â”‚
â”œâ”€â”€ main.py # Entry point of the pipeline
â””â”€â”€ requirements.txt


---

## ğŸš€ How It Works

The pipeline runs through the following steps in sequence:

1. **Data Ingestion**  
   Loads data from source into a working directory.  
   ```bash
    dataIngestion = DataIngestion(dataIngestionConfig)
    dataIngestionArtifact = dataIngestion.initiate_data_ingestion()
    ```
   
2. **Data Validation**  
   Ensures the data matches the expected schema and has no critical missing values.  
   ```bash
    dataValidation = DataValidation(dataIngestionArtifact, dataValidationConfig)
    dataValidationArtifact = dataValidation.initiate_data_validation()
    ```

3. **Data Transformation**  
   Converts raw data into model-ready format (feature scaling, encoding, etc.). 
   ```bash
    dataTransformation = DataTransformation(dataValidationArtifact, dataTransformationConfig)
    dataTransformationArtifact = dataTransformation.initiate_data_transformation()
    ```
   
4. **Model Training**  
   Trains and evaluates the machine learning model using transformed data. 
   ```bash
    modelTrainer = ModelTrainer(model_trainer_config, dataTransformationArtifact)
    modelTrainerArtifact = modelTrainer.initiate_model_trainer()
    ```
   
## âš™ï¸ Installation
1. Clone the repository
```bash

git clone https://github.com/Nivakaran-S/fraud-transaction-detection.git
cd fraud-transaction-detection

```

2. Create a virtual environment
```bash

python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

```

3Install dependencies
```bash

pip install -r requirements.txt

```

## â–¶ï¸ Running the Pipeline
To run the full training pipeline:
```bash

python main.py

```

## ğŸ“ Logging & Error Handling
- Logging: All logs are stored in the configured logging directory, making it easier to trace execution.
- Custom Exceptions: FraudTransactionException provides detailed error tracking.

## ğŸ“Š Example Outputs
Artifacts generated after pipeline execution:
- Data Ingestion Artifact â€“ Paths to ingested train/test data.
- Data Validation Artifact â€“ Validation status & report.
- Data Transformation Artifact â€“ Paths to transformed datasets & preprocessing objects.
- Model Trainer Artifact â€“ Trained model path & performance metrics.

## ğŸ§© Configuration
Configurations are defined in:
- config_entity.py â€“ Holds configuration classes for all pipeline stages.
- TrainingPipelineConfig â€“ Global pipeline configuration.

## ğŸ¤ Contributing
Pull requests are welcome. For significant changes, please open an issue first to discuss what you would like to change.
